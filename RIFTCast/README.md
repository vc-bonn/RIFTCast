# RIFTCast Lib
This library contains the core functionality of the real-time telepresence demo.

## Structure
This library has four main modules. 

* **Geometry Module**: reads and decompresses the mask data, computes a visual hull, and renders primitive maps from each view.
* **Render Module**: Takes in the visual hull information and selects appropriate cameras, loads RGB jpeg encoded images and does the projective texturing.
* **Dataloader**: A variety of dataloader that abstract the communication with the capture server or can be used to load data from disc.
* **Protocol**: A simple protocol that handles communication between the reconstruction server and client.

## Prerequisites
To run each part of the demo, the following components are needed.

### Reconstruction-Server
For the reconstruction server a linux-based Server with two GPUs is needed. The following software is needed to run and compile the system:
* python (>= 3.9)
* CUDA 12.4
* torch with CUDA support (2.4.1+cu124)
* C++17 compiler
* OpenGL dev packages, especially EGL capabilities

### Remote-Client
For the remote client a Windows system with CUDA capable GPU is required:
* python (>= 3.9)
* CUDA 12.4
* torch with CUDA support (2.4.1+cu124)
* C++17 compiler

For the VR demo (optional):
* HMD like Meta Quest Pro
* Steam
* SteamVR

## Building and running the system
### Reconstruction Server
All commands have to be executed from the root folder of ```atcg_framework```.
First, update the submodules
```
git submodule update --init --recursive
```
Configure the project using
```
cmake . -B build -DATCG_HEADLESS=On
```
Build the project
```
cmake --build build --parallel --target VCI_server
```
Run the Server
```
./bin/VCI_server
```
It reads a config file from ```TODO```. See ```Server config File``` to see the structure of this file.

### Remote Client
All commands have to be executed from the root folder of ```atcg_framework```.
First, update the submodules
```
git submodule update --init --recursive
```
Configure the project using
```
cmake . -B build
```
Build the project
```
cmake --build build --parallel --config Release --target VCI_client
```
Run the app
```
./bin/Release/VCI_client
```
A file explorer should open where you can select a config file. See ```Client Config File``` for the structure of the config file. The system will automatically compile with VR support. It will automatically start in VR mode if SteamVR is running and the Headset is connected to the computer. If no Headset can be found, it will run with a normal first-person camera controller.

### Server config File
```json
{
    "type": "VCI_REAL_TCP", // Which type of dataset
    "version": "2.2",
    "dataset": {
        "frame_count": 150,     // used for datasets loaded from disk
        "start_frame": 0,       // used for datasets loaded from disk
        "path": "",             // used for datasets loaded from disk
        "camera_path": "",      // relative to "path", used for datasets loaded from disk
        "flip_images": true,    // If Input images should be flipped (mostly true for live data, false for disk data)
        "flip_masks": true      // If masks should be flipped (mostly true for live data, false for disk data)
    },
    "reconstructor": {
        "floor_offset": 0.0,    // Offset from the floor to the calibration system (0 for live data)
        "level": 9,             // Level of visual hull grid
        "partial_masks": true   // If partial masks should be used for the visual hull
    },
    "volume": {
        "position": [0, 1.5, 0],    // Position of the reconstruction volume (center)
        "scale": 1.5                // Scale of the volume (half side length)
    },
    "server": {
        "ip": "127.0.0.1",          // This is used if the data is fetched from a server but the reconstruction runs locally
        "port": 25565
    },
	"capture_servers": {
		"ips": ["10.3.10.1", "10.3.10.2", "10.3.10.3", "10.3.10.4", "10.3.10.6"], // Ips to the capture servers
		"trigger": "10.3.10.20:8080" // Ip to the trigger
	}
}
```
The types are defined by
```c++
    enum class DatasetType
    {
        ATCG         = 0,    // Dataset generated by atcg_framework/VCI_DatasetGenerator
        VCI          = 1,    // VCI simulated data (mitsuba)
        PANOPTIC     = 2,    // Panoptic dataset format
        TCP          = 3,    // TCP server that sends images and masks
        VCI_REAL     = 4,    // Real captured VCI data (from disk)
        VCI_REAL_TCP = 5     // Real connection to the capture servers (live reconstruction)
    };
```

### Client Config File
```json
{
	"version": 1.0,
    "server": {
        "ip": "vci-gpu1.informatik.uni-bonn.de",
        "port": 25565
    }
}
```